# -*- coding: utf-8 -*-
"""Dynamic Topic Modeling -- Loading & Evaluating Models (Hw 2 Part 1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ezg9L1NVpxY9kfl-WqVF4BkV7HbzryEW

# Hw2 Part 2: 
## DTM
## Loading & Evaluating Prior Models
"""

# Commented out IPython magic to ensure Python compatibility.
# setting up our imports
import pandas as pd
import numpy

# Gensim
import gensim
from gensim.utils import simple_preprocess
import gensim.corpora as corpora
from gensim.models import ldaseqmodel
from gensim.models.wrappers import DtmModel
from gensim.corpora import Dictionary, bleicorpus
from gensim.matutils import hellinger
from gensim.models import ldaseqmodel
from gensim.corpora import Dictionary, bleicorpus
import numpy
from gensim.matutils import hellinger
import pickle
from gensim.test.utils import datapath
from gensim.corpora import Dictionary, bleicorpus
from gensim.matutils import hellinger
from gensim import corpora, models, similarities
from gensim.models.coherencemodel import CoherenceModel
from gensim.models.wrappers.dtmmodel import DtmModel

from gensim.models import callbacks
from gensim.models.callbacks import CallbackAny2Vec
from gensim.test.utils import get_tmpfile

# NLTK
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')

# spacy 
import spacy

# Plotting tools
import pyLDAvis
import pyLDAvis.gensim 
import matplotlib.pyplot as plt
from pprint import pprint
# %matplotlib inline

#!pip install playsound
from playsound import playsound

import warnings
warnings.filterwarnings("ignore",category=DeprecationWarning)

"""### Data Preprocessing"""

df = pd.read_excel('Index_fund_all.xlsx')

df1 = df[['filing_year','principal_strategies']]    # dtype('O') w. 6171 rows 

df1 = df1.dropna(axis=0)    # dtype('O') w. 5761 rows

df1.sort_values(by='filing_year')

# creating time slice
x = df1.filing_year.value_counts().sort_values()
time_slice = x.tolist()

df2 = df1.principal_strategies
tl = df2.values.tolist()    # list of strings w. 5761 strings of txt 

# lowercases, tokenizes, de-accents each sentence
def sentence_to_words(sentences):
    for sentence in sentences:
        yield(gensim.utils.simple_preprocess(sentence, deacc=True))  # deacc=True removes punctuations

wl = list(sentence_to_words(tl))    # list of strings w. 5761 strings of tokenized words 

# removing stop-words
stop_words = stopwords.words('english')
stop_words.extend(['from', 'subject', 're', 'edu', 'use','index','fund'])

def remove_stopwords(texts):
    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]

wl1 = remove_stopwords(wl)

# lemmatization - keeping only noun, adj, vb, adv
nlp = spacy.load('en', disable=['parser', 'ner'])

def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):
    texts_out = []
    for sentence in texts:
        doc = nlp(" ".join(sentence)) 
        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])
    return texts_out

wl2 = lemmatization(wl1, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])

# Create Dictionary
dict = corpora.Dictionary(wl2)

# Create Corpus
corpus = [dict.doc2bow(word) for word in wl2]
print('Number of unique tokens: %d' % len(dict))
print('Number of documents: %d' % len(corpus))

"""### Saving Corpus & Dictionary """

revNo = 1

#model_list.save('hw2p2_dtm_rev{}.gensim'.format(revNo))

corpora.MmCorpus.serialize('hw2p2_dtm_corpus_rev{}.gensim'.format(revNo), corpus)

dict.save('hw2p2_dtm_dictionary_rev{}.gensim'.format(revNo))

#playsound('COD.mp3',True)

"""### Loading Model, Corpus, & Dictionary """

loaded_model =  models.LdaModel.load('hw2p2_dtm_model_rev1.gensim')
loaded_dict = corpora.Dictionary.load('hw2p2_dtm_dictionary_rev1.gensim')
loaded_corpus = corpora.MmCorpus('hw2p2_dtm_corpus_rev1.gensim')

"""### Coherence Scores"""

topics_wrapper = loaded_model.dtm_coherence(time=0)
#texts = pickle.load(loaded_corpus)

cm_wrapper = CoherenceModel(topics=topics_wrapper, 
                            texts=loaded_corpus, 
                            dictionary=loaded_dict, 
                            coherence='c_v')

print ("C_v topic coherence")
print ("Wrapper coherence is ", cm_wrapper.get_coherence())

"""### Test Metrics """

pprint(loaded_model.print_topics(num_topics=2,num_words=1))

c = loaded_model.dtm_coherence(time=8,num_words=3)
c1 = loaded_model.dtm_coherence(time=7,num_words=3)
c2 = pd.DataFrame(c)
print(c2)

slice = 8
doc_topic, topic_term, doc_lengths, term_frequency, vocab = loaded_model.dtm_vis(loaded_corpus,time=slice)

pyLDAvis.enable_notebook()
vis_dtm = pyLDAvis.prepare(topic_term_dists=topic_term, 
                           doc_topic_dists=doc_topic, 
                           doc_lengths=doc_lengths, 
                           vocab=vocab, 
                           term_frequency=term_frequency)
print('slice = {}'.format(slice))
pyLDAvis.display(vis_dtm)

slice = 7
doc_topic, topic_term, doc_lengths, term_frequency, vocab = loaded_model.dtm_vis(loaded_corpus,time=slice)

pyLDAvis.enable_notebook()
vis_dtm = pyLDAvis.prepare(topic_term_dists=topic_term, 
                           doc_topic_dists=doc_topic, 
                           doc_lengths=doc_lengths, 
                           vocab=vocab, 
                           term_frequency=term_frequency)
print('slice = {}'.format(slice))
pyLDAvis.display(vis_dtm)

slice = 6
doc_topic, topic_term, doc_lengths, term_frequency, vocab = loaded_model.dtm_vis(loaded_corpus,time=slice)

pyLDAvis.enable_notebook()
vis_dtm = pyLDAvis.prepare(topic_term_dists=topic_term, 
                           doc_topic_dists=doc_topic, 
                           doc_lengths=doc_lengths, 
                           vocab=vocab, 
                           term_frequency=term_frequency)
print('slice = {}'.format(slice))
pyLDAvis.display(vis_dtm)

slice = 5
doc_topic, topic_term, doc_lengths, term_frequency, vocab = loaded_model.dtm_vis(loaded_corpus,time=slice)

pyLDAvis.enable_notebook()
vis_dtm = pyLDAvis.prepare(topic_term_dists=topic_term, 
                           doc_topic_dists=doc_topic, 
                           doc_lengths=doc_lengths, 
                           vocab=vocab, 
                           term_frequency=term_frequency)
print('slice = {}'.format(slice))
pyLDAvis.display(vis_dtm)

slice = 4
doc_topic, topic_term, doc_lengths, term_frequency, vocab = loaded_model.dtm_vis(loaded_corpus,time=slice)

pyLDAvis.enable_notebook()
vis_dtm = pyLDAvis.prepare(topic_term_dists=topic_term, 
                           doc_topic_dists=doc_topic, 
                           doc_lengths=doc_lengths, 
                           vocab=vocab, 
                           term_frequency=term_frequency)
print('slice = {}'.format(slice))
pyLDAvis.display(vis_dtm)

slice = 3
doc_topic, topic_term, doc_lengths, term_frequency, vocab = loaded_model.dtm_vis(loaded_corpus,time=slice)

pyLDAvis.enable_notebook()
vis_dtm = pyLDAvis.prepare(topic_term_dists=topic_term, 
                           doc_topic_dists=doc_topic, 
                           doc_lengths=doc_lengths, 
                           vocab=vocab, 
                           term_frequency=term_frequency)
print('slice = {}'.format(slice))
pyLDAvis.display(vis_dtm)

slice = 2
doc_topic, topic_term, doc_lengths, term_frequency, vocab = loaded_model.dtm_vis(loaded_corpus,time=slice)

pyLDAvis.enable_notebook()
vis_dtm = pyLDAvis.prepare(topic_term_dists=topic_term, 
                           doc_topic_dists=doc_topic, 
                           doc_lengths=doc_lengths, 
                           vocab=vocab, 
                           term_frequency=term_frequency)
print('slice = {}'.format(slice))
pyLDAvis.display(vis_dtm)

slice = 1
doc_topic, topic_term, doc_lengths, term_frequency, vocab = loaded_model.dtm_vis(loaded_corpus,time=slice)

pyLDAvis.enable_notebook()
vis_dtm = pyLDAvis.prepare(topic_term_dists=topic_term, 
                           doc_topic_dists=doc_topic, 
                           doc_lengths=doc_lengths, 
                           vocab=vocab, 
                           term_frequency=term_frequency)
print('slice = {}'.format(slice))
pyLDAvis.display(vis_dtm)

slice = 0
doc_topic, topic_term, doc_lengths, term_frequency, vocab = loaded_model.dtm_vis(loaded_corpus,time=slice)

pyLDAvis.enable_notebook()
vis_dtm = pyLDAvis.prepare(topic_term_dists=topic_term, 
                           doc_topic_dists=doc_topic, 
                           doc_lengths=doc_lengths, 
                           vocab=vocab, 
                           term_frequency=term_frequency)
print('slice = {}'.format(slice))
pyLDAvis.display(vis_dtm)

